{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/v-nitin.gupta/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Epoch 1/7\n",
      "60000/60000 [==============================] - 43s 722us/sample - loss: 0.1896 - acc: 0.9415\n",
      "Epoch 2/7\n",
      "60000/60000 [==============================] - 47s 783us/sample - loss: 0.0808 - acc: 0.9746\n",
      "Epoch 3/7\n",
      "60000/60000 [==============================] - 47s 784us/sample - loss: 0.0539 - acc: 0.9832\n",
      "Epoch 4/7\n",
      "60000/60000 [==============================] - 48s 804us/sample - loss: 0.0420 - acc: 0.9864\n",
      "Epoch 5/7\n",
      "60000/60000 [==============================] - 48s 795us/sample - loss: 0.0306 - acc: 0.9903\n",
      "Epoch 6/7\n",
      "60000/60000 [==============================] - 49s 809us/sample - loss: 0.0256 - acc: 0.9917\n",
      "Epoch 7/7\n",
      "60000/60000 [==============================] - 48s 807us/sample - loss: 0.0232 - acc: 0.9930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe6dfcb5080>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train,y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = tf.keras.utils.normalize(x_train, axis = 1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis = 1)\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(1000, activation = tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(1000, activation = tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(10, activation = tf.nn.softmax))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=7)\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 139us/sample - loss: 0.1033 - acc: 0.9769\n",
      "0.10332864905007064 0.9769\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(x_test,y_test)\n",
    "print(val_loss,val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00393124 0.02332955 0.02620568 0.02625207 0.17420356 0.17566281\n",
      "  0.28629534 0.05664824 0.51877786 0.71632322 0.77892406 0.89301644\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.05780486 0.06524513 0.16128198 0.22713296\n",
      "  0.22277047 0.32790981 0.36833534 0.3689874  0.34978968 0.32678448\n",
      "  0.368094   0.3747499  0.79066747 0.67980478 0.61494005 0.45002403\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.12250613 0.45858525 0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.32790981 0.36833534 0.3689874  0.34978968 0.32420121\n",
      "  0.15214552 0.17865984 0.25626376 0.1573102  0.12298801 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.04500225 0.4219755  0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.32790981 0.28826244 0.26543758 0.34149427 0.31128482\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.1541463  0.28272888 0.18358693 0.37314701\n",
      "  0.33153488 0.26569767 0.01601458 0.         0.05945042 0.19891229\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.0253731  0.00171577 0.22713296\n",
      "  0.33153488 0.11664776 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.20500962\n",
      "  0.33153488 0.24625638 0.00291174 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.01622378\n",
      "  0.24897876 0.32790981 0.10191096 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.04586451 0.31235677 0.32757096 0.23335172 0.14931733 0.00129164\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.10498298 0.34940902 0.3689874  0.34978968 0.15370495\n",
      "  0.04089933 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.06551419 0.27127137 0.34978968 0.32678448\n",
      "  0.245396   0.05882702 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.02333517 0.12857881 0.32549285\n",
      "  0.41390126 0.40743158 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.32161793\n",
      "  0.41390126 0.54251585 0.20001074 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.06697006 0.18959827 0.25300993 0.32678448\n",
      "  0.41390126 0.45100715 0.00625034 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.05110617 0.19182076 0.33339444 0.3689874  0.34978968 0.32678448\n",
      "  0.40899334 0.39653769 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.04117838 0.16813739\n",
      "  0.28960162 0.32790981 0.36833534 0.3689874  0.34978968 0.25961929\n",
      "  0.12760592 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.04431706 0.11961607 0.36545809 0.37314701\n",
      "  0.33153488 0.32790981 0.36833534 0.28877275 0.111988   0.00258328\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.05298497 0.42752138 0.4219755  0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.25273681 0.11646967 0.01312603 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.37491383 0.56222061\n",
      "  0.66525569 0.63253163 0.48748768 0.45852825 0.43408872 0.359873\n",
      "  0.17428513 0.01425695 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.92705966 0.82698729\n",
      "  0.74473314 0.63253163 0.4084877  0.24466922 0.22648107 0.02359823\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(x_train[0])\n",
    "\n",
    "plt.imshow(x_train[0], cmap = plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('epic_num_reader.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model('epic_num_reader.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = new_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.69061193e-20 4.74913294e-12 1.26297735e-13 ... 1.00000000e+00\n",
      "  1.00988615e-16 2.44531340e-10]\n",
      " [5.50963810e-19 1.37322683e-19 1.00000000e+00 ... 1.34020666e-15\n",
      "  7.24941399e-19 1.20410873e-26]\n",
      " [9.72243323e-14 9.99998450e-01 3.81992571e-08 ... 1.56931458e-06\n",
      "  3.65364379e-08 2.82384064e-11]\n",
      " ...\n",
      " [5.02928873e-18 1.82553733e-13 3.36361569e-15 ... 3.53849866e-11\n",
      "  1.68515223e-12 2.13144433e-11]\n",
      " [2.78193310e-18 3.43557932e-20 2.74826287e-19 ... 1.27655727e-16\n",
      "  5.80901771e-10 5.38285219e-18]\n",
      " [2.56690882e-13 6.03614827e-18 5.39467767e-16 ... 6.47570174e-23\n",
      "  2.04262822e-11 6.89410249e-18]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(np.argmax(predictions[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  785000    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  1001000   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  10010     \n",
      "=================================================================\n",
      "Total params: 1,796,010\n",
      "Trainable params: 1,796,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
